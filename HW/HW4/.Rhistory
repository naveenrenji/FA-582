setwd("~/Stevens/FA-582/FA-582/HW/HW4")
# Create the training and test sets
train_set <- oj_data[train_indices, ]
# Load the dataset
oj_data <- read.csv("OJ.csv")
#------------------------- a -------------------------------------------------------#
# Set seed for reproducibility
set.seed(123)
# Randomly select 800 observations for the training set
train_indices <- sample(1:nrow(oj_data), 800)
# Create the training and test sets
train_set <- oj_data[train_indices, ]
test_set <- oj_data[-train_indices, ]
#------------------------- a -------------------------------------------------------#
library(tree)
# Load the tree package
library(tree)
# Fit the tree model
oj_tree <- tree(Purchase ~ ., data = train_set)
# Summary of the tree
summary(oj_tree)
# Load the dataset
oj_data <- read.csv("OJ.csv")
#------------------------- a -------------------------------------------------------#
# Set seed for reproducibility
set.seed(123)
# Randomly select 800 observations for the training set
train_indices <- sample(1:nrow(oj_data), 800)
# Create the training and test sets
train_set <- oj_data[train_indices, ]
test_set <- oj_data[-train_indices, ]
#------------------------- b -------------------------------------------------------#
# Load the tree package
library(tree)
# Fit the tree model
oj_tree <- tree(Purchase ~ ., data = train_set)
# Summary of the tree
summary(oj_tree)
oj_data <- read.csv("OJ.csv")
str(oj_data)
# Load the dataset
oj_data <- read.csv("OJ.csv")
str(oj_data)
# Convert character variables to factors
oj_data$Purchase <- as.factor(oj_data$Purchase)
oj_data$Store7 <- as.factor(oj_data$Store7)
# Load the dataset
oj_data <- read.csv("OJ.csv")
str(oj_data)
# Convert character variables to factors
oj_data$Purchase <- as.factor(oj_data$Purchase)
oj_data$Store7 <- as.factor(oj_data$Store7)
#------------------------- a -------------------------------------------------------#
# Set seed for reproducibility
set.seed(123)
# Randomly select 800 observations for the training set
train_indices <- sample(1:nrow(oj_data), 800)
# Create the training and test sets
train_set <- oj_data[train_indices, ]
test_set <- oj_data[-train_indices, ]
#------------------------- b -------------------------------------------------------#
# Load the tree package
library(tree)
# Fit the tree model
oj_tree <- tree(Purchase ~ ., data = train_set)
# Summary of the tree
summary(oj_tree)
print(oj_tree)
# Plot the tree
plot(oj_tree)
# Add labels to the plot
text(oj_tree, pretty = 0)
# Predicting on the test set
test_pred <- predict(oj_tree, newdata = test_set, type = "class")
# Creating the confusion matrix
conf_matrix <- table(test_set$Purchase, test_pred)
# Calculating the test error rate
test_error_rate <- sum(diag(conf_matrix)) / sum(conf_matrix)
test_error_rate <- 1 - test_error_rate
# Predicting on the test set
test_pred <- predict(oj_tree, newdata = test_set, type = "class")
# Creating the confusion matrix
conf_matrix <- table(test_set$Purchase, test_pred)
print(conf_matrix)
# Calculating the test error rate
test_error_rate <- sum(diag(conf_matrix)) / sum(conf_matrix)
test_error_rate <- 1 - test_error_rate
print(test_error_rate)
# Perform cross-validation
cv_oj_tree <- cv.tree(oj_tree, FUN = prune.tree)
# Print the results
print(cv_oj_tree)
# Plot tree size vs cross-validated classification error rate
plot(cv_oj_tree$size, cv_oj_tree$dev, type="b",
xlab="Number of Terminal Nodes", ylab="CV Error",
main="Plot of Tree Size vs CV Error")
View(oj_data)
#-------------------------------------- a -------------------------------------------------------#
# Load the dataset
caravan_data <- read.csv("CARAVAN.csv")
# Create the training set
train_set <- caravan_data[1:1000, ]
# Create the test set
test_set <- caravan_data[1001:nrow(caravan_data), ]
#-------------------------------------- a -------------------------------------------------------#
# Load the gbm package
library(gbm)
# Fit the boosting model
set.seed(123) # for reproducibility
boosting_model <- gbm(Purchase ~ .,
distribution = "bernoulli",
data = train_set,
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.01,
n.minobsinnode = 10)
# Load the dataset
caravan_data <- read.csv("CARAVAN.csv")
str(caravan_data)
library(gbm)
# Load the dataset
caravan_data <- read.csv("CARAVAN.csv")
str(caravan_data)
# Convert 'Purchase' from character to factor and then to binary numeric
caravan_data$Purchase <- as.numeric(as.factor(caravan_data$Purchase)) - 1
# Check for variables with no variation and remove them
no_variation <- sapply(caravan_data, function(x) length(unique(x)) == 1)
caravan_data <- caravan_data[, !no_variation]
#-------------------------------------- a -------------------------------------------------------#
# Create the training set
train_set <- caravan_data[1:1000, ]
# Create the test set
test_set <- caravan_data[1001:nrow(caravan_data), ]
#-------------------------------------- b -------------------------------------------------------#
# Fit the boosting model
set.seed(123) # for reproducibility
boosting_model <- gbm(Purchase ~ .,
distribution = "bernoulli",
data = train_set,
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.01,
n.minobsinnode = 10)
# Summary of the boosting model to see most important predictors
summary(boosting_model)
#-------------------------------------- a -------------------------------------------------------#
#-------------------------------------- a -------------------------------------------------------#
#-------------------------------------- a -------------------------------------------------------#
#-------------------------------------- a -------------------------------------------------------#
# Predicting on the test set using the boosting model
test_pred_prob <- predict(boosting_model, newdata = test_set, n.trees = 1000, type = "response")
# Predicting a purchase if the estimated probability is greater than 20%
test_pred_class <- ifelse(test_pred_prob > 0.20, 1, 0)
# Creating a confusion matrix
conf_matrix <- table(test_set$Purchase, test_pred_class)
print(conf_matrix)
# Calculating the fraction of correct predictions among those predicted to make a purchase
purchase_predicted_correctly <- conf_matrix[2, 2]
purchase_predicted_total <- sum(conf_matrix[, 2])
fraction_correct <- purchase_predicted_correctly / purchase_predicted_total
print(fraction_correct)
# Fitting logistic regression model
logistic_model <- glm(Purchase ~ ., family = binomial, data = train_set)
# Predicting on the test set using the logistic regression model
logistic_pred_prob <- predict(logistic_model, newdata = test_set, type = "response")
logistic_pred_class <- ifelse(logistic_pred_prob > 0.20, 1, 0)  # Using the same 20% threshold
# Creating a confusion matrix for logistic regression
conf_matrix_logistic <- table(test_set$Purchase, logistic_pred_class)
print(conf_matrix_logistic)
# Calculating the fraction of correct predictions among those predicted to make a purchase
purchase_predicted_correctly_log <- conf_matrix_logistic[2, 2]
purchase_predicted_total_log <- sum(conf_matrix_logistic[, 2])
fraction_correct_log <- purchase_predicted_correctly_log / purchase_predicted_total_log
print(fraction_correct_log)
# Calculate precision for logistic regression
logistic_precision <- 58 / (58 + 350)
print(logistic_precision)
# Predicting on the test set using the boosting model
test_pred_prob <- predict(boosting_model, newdata = test_set, n.trees = 1000, type = "response")
# Predicting a purchase if the estimated probability is greater than 20%
test_pred_class <- ifelse(test_pred_prob > 0.20, 1, 0)
# Creating a confusion matrix
conf_matrix <- table(test_set$Purchase, test_pred_class)
print(conf_matrix)
# Calculating the fraction of correct predictions among those predicted to make a purchase
purchase_predicted_correctly <- conf_matrix[2, 2]
purchase_predicted_total <- sum(conf_matrix[, 2])
fraction_correct <- purchase_predicted_correctly / purchase_predicted_total
print(fraction_correct)
# Fitting logistic regression model
logistic_model <- glm(Purchase ~ ., family = binomial, data = train_set)
# Predicting on the test set using the logistic regression model
logistic_pred_prob <- predict(logistic_model, newdata = test_set, type = "response")
logistic_pred_class <- ifelse(logistic_pred_prob > 0.20, 1, 0)  # Using the same 20% threshold
# Creating a confusion matrix for logistic regression
conf_matrix_logistic <- table(test_set$Purchase, logistic_pred_class)
print(conf_matrix_logistic)
# Calculating the fraction of correct predictions in log reg
purchase_predicted_correctly_log <- conf_matrix_logistic[2, 2]
purchase_predicted_total_log <- sum(conf_matrix_logistic[, 2])
fraction_correct_log <- purchase_predicted_correctly_log / purchase_predicted_total_log
print(fraction_correct_log)
str(data)
#-------------------------------------- a -------------------------------------------------------#
# Set seed for reproducibility
set.seed(123)
# Number of observations per class and total variables
n <- 20
p <- 50
# Generating data for three classes
class_1 <- matrix(rnorm(n * p, mean = 0), nrow = n)
class_2 <- matrix(rnorm(n * p, mean = 1), nrow = n)
class_3 <- matrix(rnorm(n * p, mean = 2), nrow = n)
# Combining the classes into one data set
data <- rbind(class_1, class_2, class_3)
str(data)
#-------------------------------------- a -------------------------------------------------------#
# Set seed for reproducibility
set.seed(123)
# Number of observations per class and total variables
n <- 20
p <- 50
# Generating data for three classes
class_1 <- matrix(rnorm(n * p, mean = 0), nrow = n)
class_2 <- matrix(rnorm(n * p, mean = 1), nrow = n)
class_3 <- matrix(rnorm(n * p, mean = 2), nrow = n)
# Combining the classes into one data set
data <- rbind(class_1, class_2, class_3)
str(data)
#-------------------------------------- b -------------------------------------------------------#
# Perform PCA
pca_result <- prcomp(data, scale. = TRUE)
# Create a data frame with the PCA scores and class labels
pca_scores <- data.frame(pca_result$x[,1:2])
pca_scores$class <- rep(1:3, each = 20)
# Plotting the first two principal components
library(ggplot2)
ggplot(pca_scores, aes(x = PC1, y = PC2, color = factor(class))) +
geom_point() +
ggtitle("PCA of Simulated Data") +
theme_minimal() +
labs(color = "Class")
#-------------------------------------- c -------------------------------------------------------#
# Perform K-means clustering
set.seed(123)
kmeans_result <- kmeans(data, centers = 3)
# Compare K-means clusters to true class labels
comparison_table <- table(TrueLabels = pca_scores$class, Cluster = kmeans_result$cluster)
print(comparison_table)
set.seed(123) # Set a random seed for reproducibility
kmeans_result_k2 <- kmeans(data, centers = 2)
# Print the resulting clusters
print(kmeans_result_k2$cluster)
set.seed(123) # Set a random seed for reproducibility
kmeans_result_k2 <- kmeans(data, centers = 2)
# Print the resulting clusters
print(kmeans_result_k2$cluster)
# Compare K-means clusters to true class labels
comparison_table_k2 <- table(TrueLabels = pca_scores$class, Cluster = kmeans_result_k2$cluster)
print(comparison_table_2)
set.seed(123) # Set a random seed for reproducibility
kmeans_result_k2 <- kmeans(data, centers = 2)
# Print the resulting clusters
print(kmeans_result_k2$cluster)
# Compare K-means clusters to true class labels
comparison_table_k2 <- table(TrueLabels = pca_scores$class, Cluster = kmeans_result_k2$cluster)
print(comparison_table_k2)
#-------------------------------------- e -------------------------------------------------------#
set.seed(123) # Set a random seed for reproducibility
kmeans_result_k24 <- kmeans(data, centers = 4)
# Print the resulting clusters
print(kmeans_result_k4$cluster)
set.seed(123) # Set a random seed for reproducibility
kmeans_result_k2 <- kmeans(data, centers = 2)
# Print the resulting clusters
print(kmeans_result_k2$cluster)
# Compare K-means clusters to true class labels
comparison_table_k2 <- table(TrueLabels = pca_scores$class, Cluster = kmeans_result_k2$cluster)
print(comparison_table_k2)
#-------------------------------------- e -------------------------------------------------------#
set.seed(123) # Set a random seed for reproducibility
kmeans_result_k4 <- kmeans(data, centers = 4)
# Print the resulting clusters
print(kmeans_result_k4$cluster)
# Compare K-means clusters to true class labels
comparison_table_k4 <- table(TrueLabels = pca_scores$class, Cluster = kmeans_result_k4$cluster)
print(comparison_table_k4)
# Extracting the first two principal components
pca_scores_2d <- pca_result$x[, 1:2]
# Perform K-means clustering on the PCA scores
set.seed(123) # Set a random seed for reproducibility
kmeans_result_pca <- kmeans(pca_scores_2d, centers = 3)
# Print the resulting clusters
print(kmeans_result_pca$cluster)
# Compare K-means clusters to true class labels
comparison_table_pca <- table(TrueLabels = pca_scores$class, Cluster = kmeans_result_pca$cluster)
print(comparison_table_pca)
#-------------------------------------- a -------------------------------------------------------#
# Set seed for reproducibility
set.seed(123)
# Number of observations per class and total variables
n <- 20
p <- 50
# Generating data for three classes
class_1 <- matrix(rnorm(n * p, mean = 0), nrow = n)
class_2 <- matrix(rnorm(n * p, mean = 1), nrow = n)
class_3 <- matrix(rnorm(n * p, mean = 2), nrow = n)
# Combining the classes into one data set
data <- rbind(class_1, class_2, class_3)
str(data)
#-------------------------------------- b -------------------------------------------------------#
# Perform PCA
pca_result <- prcomp(data, scale. = TRUE)
# Create a data frame with the PCA scores and class labels
pca_scores <- data.frame(pca_result$x[,1:2])
pca_scores$class <- rep(1:3, each = 20)
# Plotting the first two principal components
library(ggplot2)
ggplot(pca_scores, aes(x = PC1, y = PC2, color = factor(class))) +
geom_point() +
ggtitle("PCA of Simulated Data") +
theme_minimal() +
labs(color = "Class")
# Scaling the data
data_scaled <- scale(data)
# Perform K-means clustering on the scaled data
set.seed(123) # Set a random seed for reproducibility
kmeans_result_scaled <- kmeans(data_scaled, centers = 3)
# Print the resulting clusters
print(kmeans_result_scaled$cluster)
# Compare K-means clusters to true class labels
comparison_table_scaled <- table(TrueLabels = rep(1:3, each = 20), Cluster = kmeans_result_scaled$cluster)
print(comparison_table_scaled)
